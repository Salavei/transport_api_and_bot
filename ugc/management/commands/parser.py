import requests
from bs4 import BeautifulSoup
import re


def parser_time_wait(hah, hah_two, left, right, station):
    if hah == None:
        all_time = ' ‚ùóÔ∏è–¢–∞–∫–æ–π –æ—Ç–∞–Ω–æ–≤–∫–∏ –≤ —ç—Ç–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç‚ùóÔ∏è'
    else:
        r = requests.get(hah, headers={
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.2 Safari/605.1.15',
            'Accept-Language': 'ru',
        })
        html = r.text
        soup = BeautifulSoup(html, 'lxml')
        take_for_was_and_now = soup.find_all('div', {"class": "content-block-desktop"})
        take_for_will_be = soup.find_all('span', {"class": "future"})
        for q in take_for_was_and_now:
            soup2 = BeautifulSoup(str(q), 'lxml')
            now = soup2.find('span', {"class": "future"})
        for q in take_for_will_be:
            soup2 = BeautifulSoup(str(q), 'lxml')
            will_be = soup2.find('span')
            all_time = [' '.join(now.text.split()), ' '.join(will_be.text.split())]
    if hah_two == None:
        all_time_two = ' ‚ùóÔ∏è–¢–∞–∫–æ–π –æ—Ç–∞–Ω–æ–≤–∫–∏ –≤ —ç—Ç–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç‚ùóÔ∏è'
    else:
        r_two = requests.get(hah_two, headers={
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.2 Safari/605.1.15',
            'Accept-Language': 'ru',
        })
        html_two = r_two.text
        soup_two = BeautifulSoup(html_two, 'lxml')
        take_for_was_and_now_two = soup_two.find_all('div', {"class": "content-block-desktop"})
        take_for_will_be_two = soup_two.find_all('span', {"class": "future"})
        for q in take_for_was_and_now_two:
            soup2 = BeautifulSoup(str(q), 'lxml')
            now = soup2.find('span', {"class": "future"})
        for q in take_for_will_be_two:
            soup2 = BeautifulSoup(str(q), 'lxml')
            will_be = soup2.find('span')
            all_time_two = [' '.join(now.text.split()), ' '.join(will_be.text.split())]
    return f"‚¨ÖÔ∏è{' '.join(left.text.split())}\nüïê{all_time} \n", f"\n‚û°Ô∏è{' '.join(right.text.split())}\nüïê{all_time_two}"


def parser_station(transport):
    bus = ['–∞–≤—Ç–æ–±—É—Å', '–ê–í–¢–û–ë–£–°', 'autobus', '–∞–≤—Ç–∏–∫', '–æ–≤—Ç–æ–±—É—Å']
    trum = ['–¢—Ä–∞–º–≤–∞–π', '—Ç—Ä–∞–º', '–¢–†–ê–ú–í–ê–ô', 'tram', '—Ç—Ä–æ–º–≤–∞–π']
    trami = ['–¢—Ä–æ–ª–ª–µ–π–±—É—Å', '—Ç—Ä–∞–ª–µ—É–π–±—É—Å', '—Ç—Ä–∞–ª–∏–∫', 'trolleybus', '—Ç—Ä–æ–ª–ª–µ–π–±—É—Å']
    metr = ['–º–µ—Ç—Ä–æ', '–ú–ï–¢–†–û', '–ú–µ—Ç—Ä–æ', 'metro']
    if transport in bus:
        transport = 'autobus'
    elif transport in trami:
        transport = 'trolleybus'
    elif transport in trum:
        transport = 'tram'
    elif transport in metr:
        transport = 'metro'
    else:
        print('—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')
    return transport


def parser_station_n(transport, number_transport, station):
    transport = parser_station(transport)
    station = station

    url = f'https://kogda.by/routes/minsk/{transport}/{number_transport}'
    r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    html = r.text
    soup = BeautifulSoup(html, 'lxml')

    left = soup.find_all('div', {"id": "direction-0-heading"})
    right = soup.find_all('div', {"id": "direction-1-heading"})

    for q in left:
        soup2 = BeautifulSoup(str(q), 'lxml')
        send_left_station = soup2.find('a').contents[0]
    for q in right:
        soup2 = BeautifulSoup(str(q), 'lxml')
        second_right_station = soup2.find('a').contents[0]

    first_way = soup.find_all('div', {"id": "direction-0"})
    second_way = soup.find_all('div', {"id": "direction-1"})

    for q in first_way:
        first_second_way = q.find_all('ul', {"class": "list-group"})
        for q in first_second_way:
            if q.find("a", string=re.compile(station)) == None:
                cc = None
            else:
                hah = q.find("a", string=re.compile(station)).get('href')
                cc = hah
    for q in second_way:
        second_second_way = q.find_all('ul', {"class": "list-group"})
        for q in second_second_way:
            if q.find("a", string=re.compile(station)) == None:
                hah_two = None
            else:
                hah_two = q.find("a", string=re.compile(station)).get('href')
        return parser_time_wait(cc, hah_two, send_left_station, second_right_station, station)


def parser_all_station(transport, number_transport):
    transport = parser_station(transport)
    url = f'https://kogda.by/routes/minsk/{transport}/{number_transport}'
    r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    html = r.text
    soup = BeautifulSoup(html, 'lxml')
    firs_all_station = soup.find('ul', {"class": "list-group"}).text
    second_all_station = soup.find('div', {"id": "direction-1"}).text
    return f"‚¨ÖÔ∏è {' '.join(firs_all_station.split())} \n \n‚û°Ô∏è {' '.join(second_all_station.split())}"
